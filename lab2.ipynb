{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wmCbxoDrADcF"
   },
   "source": [
    "# Google Colab setup with Google Drive folder\n",
    "\n",
    "This notebook provides the code you need to set up Google Colab to run and import files from within a Google Drive folder.\n",
    "\n",
    "This will allow you to upload assignment code to your Google Drive and then run the code on Google Colab machines (with free GPUs if needed). \n",
    "\n",
    "You will need to create a folder in your Google Drive to hold your assignments and you will need to open Colaboratory within this folder before running the set up code (check the link above to see how)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zWhrmhqVCyGH"
   },
   "source": [
    "# Mount Google Drive\n",
    "\n",
    "This will allow the Colab machine to access Google Drive folders by mounting the drive on the machine. You will be asked to copy and paste an authentication code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wv2oKmF9AJtI"
   },
   "outputs": [],
   "source": [
    "# Skip this step because I'm not using Colab.\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kKGxaMcmP_Et"
   },
   "outputs": [],
   "source": [
    "# ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Qs04PPwDOFy"
   },
   "source": [
    "# Change directory to allow imports\n",
    "\n",
    "\n",
    "As noted above, you should create a Google Drive folder to hold all your assignment files. You will need to add this code to the top of any python notebook you run to be able to import python files from your drive assignment folder (you should change the file path below to be your own assignment folder). Following the hand-out, you should have a directory \"SFU_CMPT_CV_lab2\" on g-drive, which should have a directory \"data\", which contains three tar.gz files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UA2-UyfpEc9O"
   },
   "outputs": [],
   "source": [
    "# Skip this step because I'm not using Colab.\n",
    "# import os\n",
    "# os.chdir(\"/content/gdrive/My Drive/SFU_CMPT_CV_lab2\")\n",
    "\n",
    "!cd /scratch/MJ/762-Assignment-2-Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gyRCWAIyRHWc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[0m\u001B[01;34m__pycache__\u001B[0m/      dataset_test.py       epoch_visualizer.py  model_test.py\n",
      "\u001B[01;34mcheckpoints.old\u001B[0m/  densenet.py           infer.py             requirements.txt\n",
      "constant.py       densenet_test.py      lab2.ipynb           train.py\n",
      "\u001B[01;34mdata\u001B[0m/             epoch_logger.py       \u001B[01;34mlogs\u001B[0m/\n",
      "dataset.py        epoch_logger_test.py  model.py\n"
     ]
    }
   ],
   "source": [
    "!ls # Check if this is your folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SJOCaUMilRz_"
   },
   "source": [
    "# Copy data to local dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "90MxG_eRla0W"
   },
   "outputs": [],
   "source": [
    "# !mkdir /data\n",
    "# !cp data/cifar100.tar.gz /data/\n",
    "# !tar -xf /data/cifar100.tar.gz -C /data/\n",
    "# !cp data/test.tar.gz /data\n",
    "# !tar -xf /data/test.tar.gz -C /data\n",
    "# !cp data/train.tar.gz /data\n",
    "# !tar -xf /data/train.tar.gz -C /data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XvFEFItpl98p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[0m\u001B[01;34mcifar100\u001B[0m/  \u001B[01;31mcifar100.tar.gz\u001B[0m  \u001B[01;34mtest\u001B[0m/  \u001B[01;31mtest.tar.gz\u001B[0m  \u001B[01;34mtrain\u001B[0m/  \u001B[01;31mtrain.tar.gz\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!ls data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activate virtual environment\n",
    "\n",
    "The codebase requires at least Python 3.8 because of the ubiquitous `typing.Final`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!source /scratch/MJ/venv/762-Assignment-2-Code/bin/activate.fish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DDU5aVgR9QBx"
   },
   "source": [
    "# Set up GPU and PyTorch\n",
    "\n",
    "First, ensure that your notebook on Colaboratory is set up to use GPU. After opening the notebook on Colaboratory, go to Edit>Notebook settings, select Python 3 under \"Runtime type,\" select GPU under \"Hardware accelerator,\" and save.\n",
    "\n",
    "Next, install PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kjbQtzKT9Uc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.7.1)\n",
      "Requirement already satisfied: torchvision in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (0.8.2)\n",
      "Requirement already satisfied: jupyterlab in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (3.0.7)\n",
      "Requirement already satisfied: matplotlib in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (3.3.4)\n",
      "Requirement already satisfied: jupyter-server~=1.2 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from jupyterlab->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: ipython in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from jupyterlab->-r requirements.txt (line 3)) (7.20.0)\n",
      "Requirement already satisfied: nbclassic~=0.2 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from jupyterlab->-r requirements.txt (line 3)) (0.2.6)\n",
      "Requirement already satisfied: jinja2>=2.10 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from jupyterlab->-r requirements.txt (line 3)) (2.11.3)\n",
      "Requirement already satisfied: packaging in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from jupyterlab->-r requirements.txt (line 3)) (20.9)\n",
      "Requirement already satisfied: tornado>=6.1.0 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from jupyterlab->-r requirements.txt (line 3)) (6.1)\n",
      "Requirement already satisfied: jupyter-core in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from jupyterlab->-r requirements.txt (line 3)) (4.7.1)\n",
      "Requirement already satisfied: jupyterlab-server~=2.0 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from jupyterlab->-r requirements.txt (line 3)) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from jinja2>=2.10->jupyterlab->-r requirements.txt (line 3)) (1.1.1)\n",
      "Requirement already satisfied: nbformat in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from jupyter-server~=1.2->jupyterlab->-r requirements.txt (line 3)) (5.1.2)\n",
      "Requirement already satisfied: jupyter-client>=6.1.1 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from jupyter-server~=1.2->jupyterlab->-r requirements.txt (line 3)) (6.1.11)\n",
      "Requirement already satisfied: prometheus-client in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from jupyter-server~=1.2->jupyterlab->-r requirements.txt (line 3)) (0.9.0)\n",
      "Requirement already satisfied: anyio>=2.0.2 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from jupyter-server~=1.2->jupyterlab->-r requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: Send2Trash in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from jupyter-server~=1.2->jupyterlab->-r requirements.txt (line 3)) (1.5.0)\n",
      "Requirement already satisfied: ipython-genutils in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from jupyter-server~=1.2->jupyterlab->-r requirements.txt (line 3)) (0.2.0)\n",
      "Requirement already satisfied: nbconvert in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from jupyter-server~=1.2->jupyterlab->-r requirements.txt (line 3)) (6.0.7)\n",
      "Requirement already satisfied: traitlets>=4.2.1 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from jupyter-server~=1.2->jupyterlab->-r requirements.txt (line 3)) (5.0.5)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from jupyter-server~=1.2->jupyterlab->-r requirements.txt (line 3)) (0.9.2)\n",
      "Requirement already satisfied: pyzmq>=17 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from jupyter-server~=1.2->jupyterlab->-r requirements.txt (line 3)) (22.0.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from anyio>=2.0.2->jupyter-server~=1.2->jupyterlab->-r requirements.txt (line 3)) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from anyio>=2.0.2->jupyter-server~=1.2->jupyterlab->-r requirements.txt (line 3)) (2.10)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from jupyter-client>=6.1.1->jupyter-server~=1.2->jupyterlab->-r requirements.txt (line 3)) (2.8.1)\n",
      "Requirement already satisfied: json5 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from jupyterlab-server~=2.0->jupyterlab->-r requirements.txt (line 3)) (0.9.5)\n",
      "Requirement already satisfied: jsonschema>=3.0.1 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from jupyterlab-server~=2.0->jupyterlab->-r requirements.txt (line 3)) (3.2.0)\n",
      "Requirement already satisfied: babel in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from jupyterlab-server~=2.0->jupyterlab->-r requirements.txt (line 3)) (2.9.0)\n",
      "Requirement already satisfied: requests in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from jupyterlab-server~=2.0->jupyterlab->-r requirements.txt (line 3)) (2.25.1)\n",
      "Requirement already satisfied: six>=1.11.0 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab->-r requirements.txt (line 3)) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab->-r requirements.txt (line 3)) (52.0.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab->-r requirements.txt (line 3)) (20.3.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab->-r requirements.txt (line 3)) (0.17.3)\n",
      "Requirement already satisfied: notebook<7 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from nbclassic~=0.2->jupyterlab->-r requirements.txt (line 3)) (6.2.0)\n",
      "Requirement already satisfied: ipykernel in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from notebook<7->nbclassic~=0.2->jupyterlab->-r requirements.txt (line 3)) (5.4.3)\n",
      "Requirement already satisfied: argon2-cffi in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from notebook<7->nbclassic~=0.2->jupyterlab->-r requirements.txt (line 3)) (20.1.0)\n",
      "Requirement already satisfied: ptyprocess in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from terminado>=0.8.3->jupyter-server~=1.2->jupyterlab->-r requirements.txt (line 3)) (0.7.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 4)) (1.20.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 4)) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 4)) (8.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 4)) (2.4.7)\n",
      "Requirement already satisfied: typing-extensions in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from torch->-r requirements.txt (line 1)) (3.7.4.3)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from argon2-cffi->notebook<7->nbclassic~=0.2->jupyterlab->-r requirements.txt (line 3)) (1.14.4)\n",
      "Requirement already satisfied: pycparser in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->notebook<7->nbclassic~=0.2->jupyterlab->-r requirements.txt (line 3)) (2.20)\n",
      "Requirement already satisfied: pytz>=2015.7 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from babel->jupyterlab-server~=2.0->jupyterlab->-r requirements.txt (line 3)) (2021.1)\n",
      "Requirement already satisfied: pygments in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from ipython->jupyterlab->-r requirements.txt (line 3)) (2.7.4)\n",
      "Requirement already satisfied: pexpect>4.3 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from ipython->jupyterlab->-r requirements.txt (line 3)) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from ipython->jupyterlab->-r requirements.txt (line 3)) (3.0.14)\n",
      "Requirement already satisfied: jedi>=0.16 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from ipython->jupyterlab->-r requirements.txt (line 3)) (0.18.0)\n",
      "Requirement already satisfied: backcall in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from ipython->jupyterlab->-r requirements.txt (line 3)) (0.2.0)\n",
      "Requirement already satisfied: decorator in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from ipython->jupyterlab->-r requirements.txt (line 3)) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from ipython->jupyterlab->-r requirements.txt (line 3)) (0.7.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from jedi>=0.16->ipython->jupyterlab->-r requirements.txt (line 3)) (0.8.1)\n",
      "Requirement already satisfied: wcwidth in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->jupyterlab->-r requirements.txt (line 3)) (0.2.5)\n",
      "Requirement already satisfied: jupyterlab-pygments in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from nbconvert->jupyter-server~=1.2->jupyterlab->-r requirements.txt (line 3)) (0.1.2)\n",
      "Requirement already satisfied: testpath in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from nbconvert->jupyter-server~=1.2->jupyterlab->-r requirements.txt (line 3)) (0.4.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from nbconvert->jupyter-server~=1.2->jupyterlab->-r requirements.txt (line 3)) (1.4.3)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from nbconvert->jupyter-server~=1.2->jupyterlab->-r requirements.txt (line 3)) (0.8.4)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from nbconvert->jupyter-server~=1.2->jupyterlab->-r requirements.txt (line 3)) (0.3)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from nbconvert->jupyter-server~=1.2->jupyterlab->-r requirements.txt (line 3)) (0.5.2)\n",
      "Requirement already satisfied: bleach in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from nbconvert->jupyter-server~=1.2->jupyterlab->-r requirements.txt (line 3)) (3.3.0)\n",
      "Requirement already satisfied: defusedxml in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from nbconvert->jupyter-server~=1.2->jupyterlab->-r requirements.txt (line 3)) (0.6.0)\n",
      "Requirement already satisfied: nest-asyncio in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->jupyter-server~=1.2->jupyterlab->-r requirements.txt (line 3)) (1.5.1)\n",
      "Requirement already satisfied: async-generator in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->jupyter-server~=1.2->jupyterlab->-r requirements.txt (line 3)) (1.10)\n",
      "Requirement already satisfied: webencodings in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from bleach->nbconvert->jupyter-server~=1.2->jupyterlab->-r requirements.txt (line 3)) (0.5.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from requests->jupyterlab-server~=2.0->jupyterlab->-r requirements.txt (line 3)) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from requests->jupyterlab-server~=2.0->jupyterlab->-r requirements.txt (line 3)) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /scratch/MJ/venv/762-Assignment-2-Code/lib/python3.8/site-packages (from requests->jupyterlab-server~=2.0->jupyterlab->-r requirements.txt (line 3)) (1.26.3)\n"
     ]
    }
   ],
   "source": [
    "# !pip3 install torch torchvision\n",
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u_BekZYY9Vzx"
   },
   "source": [
    "Make sure that pytorch is installed and works with GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8TXSJWQa9efx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.Tensor([1]).cuda()\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OEeRNsCjRXZK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qChgLJERsvZP"
   },
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IlyCnvf6WzjR"
   },
   "outputs": [],
   "source": [
    "\"\"\"Headers\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import sys\n",
    "if sys.version_info[0] == 2:\n",
    "    import cPickle as pickle\n",
    "else:\n",
    "    import pickle\n",
    "\n",
    "import torch.utils.data as data\n",
    "from torchvision.datasets.utils import download_url, check_integrity\n",
    "\n",
    "import csv\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os.path\n",
    "import sys\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "np.random.seed(111)\n",
    "torch.cuda.manual_seed_all(111)\n",
    "torch.manual_seed(111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "137GhZMrcTuj"
   },
   "source": [
    "\n",
    "\n",
    "## **Just execute the cell below. This is the dataloader. DO NOT CHANGE ANYTHING IN HERE!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "URUH4fzzWqKr"
   },
   "outputs": [],
   "source": [
    "\"\"\"\"\"\"\n",
    "\n",
    "# I've moved the dataset script into an external module.\n",
    "from dataset import CIFAR100_SFU_CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JpFMv7HtcII4"
   },
   "source": [
    "This file has been adapted from the easy-to-use tutorial released by PyTorch:\n",
    "http://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "\n",
    "Training an image classifier\n",
    "----------------------------\n",
    "\n",
    "We will do the following steps in order:\n",
    "\n",
    "1. Load the CIFAR100_SFU_CV training, validation and test datasets using\n",
    "   torchvision. Use torchvision.transforms to apply transforms on the\n",
    "   dataset.\n",
    "2. Define a Convolution Neural Network - BaseNet\n",
    "3. Define a loss function and optimizer\n",
    "4. Train the network on training data and check performance on val set.\n",
    "   Plot train loss and validation accuracies.\n",
    "5. Try the network on test data and create .csv file for submission to kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ld6juH34dWWq"
   },
   "outputs": [],
   "source": [
    "# These settings are unused.\n",
    "# Refer to `train.py` and `constant.py` for those settings.\n",
    "\n",
    "# <<TODO#5>> Based on the val set performance, decide how many\n",
    "# epochs are apt for your model.\n",
    "# ---------\n",
    "# EPOCHS = 15\n",
    "# ---------\n",
    "\n",
    "# IS_GPU = True\n",
    "# TEST_BS = 256\n",
    "# TOTAL_CLASSES = 100\n",
    "# TRAIN_BS = 32\n",
    "# PATH_TO_CIFAR100_SFU_CV = \"/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0ENlTTMi-qFD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_cs543  train_cs543\n"
     ]
    }
   ],
   "source": [
    "!ls data/cifar100/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d57CSAj1dfix"
   },
   "outputs": [],
   "source": [
    "# Unused in this notebook because it's inefficient (wastes 30 more seconds per epoch; not even using `torch.no_grad()`; should not mix numpy and torch functions).\n",
    "# Refer to the `MARK: Validation` part of `train.py` for validation accuracy calculation.\n",
    "\n",
    "# from train import calculate_val_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aq2qOUaJeAWJ"
   },
   "source": [
    "1.** Loading CIFAR100_SFU_CV**\n",
    "\n",
    "We modify the dataset to create CIFAR100_SFU_CV dataset which consist of 45000 training images (450 of each class), 5000 validation images (50 of each class) and 10000 test images (100 of each class). The train and val datasets have labels while all the labels in the test set are set to 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C2UcDZmtdfq3"
   },
   "outputs": [],
   "source": [
    "# The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "# Using transforms.ToTensor(), transform them to Tensors of normalized range\n",
    "# [-1, 1].\n",
    "\n",
    "# Refer to `train.py` and `constant.py` for transformations and datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define a Convolution Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5b_fBznndp4W"
   },
   "outputs": [],
   "source": [
    "# Refer to `densenet.py` for my network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Define a Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zAZjIcLOdp-W"
   },
   "outputs": [],
   "source": [
    "# Refer to the `main` function in `train.py`.\n",
    "# I used Cross-Entropy loss and SGD with weight decay and a high momentum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Train the network and save the training log to a file\n",
    "\n",
    "The DenseNet model is very deep and can take hours to train.\n",
    "\n",
    "Don't save the training log to this notebook because they are very long (I have 400 epochs).\n",
    "In fact, it's recommended to NOT use Jupyter notebook for training for stability reasons.\n",
    "Better alternatives include Docker containers, `screen`, and `tmux`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir checkpoints\n",
    "!py train.py --train_batch_size=300 > checkpoints/log.txt\n",
    "# Refer to train.py for training loop.\n",
    "# All training logs and weights can be obtained at: https://github.com/MacJim/CMPT-762-Assignment-2-Checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Visualize training and validation losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ku7eF366dyUP"
   },
   "outputs": [],
   "source": [
    "!python epoch_visualizer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Try the network on test data, and create .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v1GE8t3mRdy9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /scratch/MJ/762-Assignment-2-Code\n"
     ]
    }
   ],
   "source": [
    "!python infer.py --checkpoint_filename=checkpoints/400.pth --csv_filename=0.4-300batch-predictions.csv\n",
    "# Refer to `infer.py` for the inference process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "og2F2MLhs7L6"
   },
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "prD0eXGpdoCR"
   },
   "outputs": [],
   "source": [
    "\"\"\"Headers\"\"\"\n",
    "import os\n",
    "import os.path as osp\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P6CJz7OM0J9Z"
   },
   "source": [
    "# Pre-Trained Model\n",
    "\n",
    "TODO1. Load pretrained resnet model. Experiment with different models. \n",
    "\n",
    "TODO2: Replace last fc layer\n",
    "\n",
    "TODO3. Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HUdo6AkH0maX"
   },
   "outputs": [],
   "source": [
    "class PreTrainedResNet(nn.Module):\n",
    "  def __init__(self, num_classes: int, feature_extracting: bool):\n",
    "    super(PreTrainedResNet, self).__init__()\n",
    "    \n",
    "    # MARK: 1. Load pre-trained ResNet Model\n",
    "    self.resnet18 = models.resnet18(pretrained=True)\n",
    "\n",
    "    # Set gradients to false (freeze)\n",
    "    if feature_extracting:\n",
    "      for param in self.resnet18.parameters():\n",
    "          param.requires_grad = False\n",
    "    \n",
    "    # Replace last fc layer\n",
    "    num_feats = self.resnet18.fc.in_features\n",
    "\n",
    "    # MARK: 2: Replace fc layer in resnet to a linear layer of size (num_feats, num_classes)\n",
    "    self.resnet18.fc = nn.Linear(num_feats, num_classes)\n",
    "\n",
    "  def forward(self, x):\n",
    "    # MARK: 3. Forward pass x through the model\n",
    "    x = self.resnet18(x)\n",
    "    return x\n",
    "\n",
    "  def set_train_last_only(self, new_val: bool):\n",
    "      for param in self.resnet18.parameters():\n",
    "          if new_val:\n",
    "              param.requires_grad = False\n",
    "          else:\n",
    "              param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y_DRbNt8Jask"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ujUNEVsEvWwv"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, scheduler, criterion, epoch, num_epochs):\n",
    "  model.train()\n",
    "  epoch_loss = 0.0\n",
    "  epoch_acc = 0.0\n",
    "  \n",
    "  for batch_idx, (images, labels) in enumerate(dataloaders['train']):\n",
    "    #zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #move to GPU\n",
    "    images, labels = images.cuda(), labels.cuda()\n",
    "    \n",
    "    #forward\n",
    "    outputs = model.forward(images)\n",
    "    \n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    _, preds = torch.max(outputs.data, 1)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    epoch_loss += loss.item()\n",
    "    epoch_acc += torch.sum(preds == labels).item()\n",
    "\n",
    "  scheduler.step()\n",
    "\n",
    "  epoch_loss /= dataset_sizes['train']\n",
    "  epoch_acc /= dataset_sizes['train']\n",
    "  \n",
    "  print('TRAINING Epoch %d/%d Loss %.4f Accuracy %.4f' % (epoch, num_epochs, epoch_loss, epoch_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mAbNgE4r7vm-"
   },
   "source": [
    "# Main\n",
    "\n",
    "1. Vary hyperparams\n",
    "2. Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oZkI3scVWjOQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING Epoch 1/70 Loss 0.1687 Accuracy 0.0087\n",
      "TRAINING Epoch 2/70 Loss 0.1575 Accuracy 0.0393\n",
      "TRAINING Epoch 3/70 Loss 0.1477 Accuracy 0.1160\n",
      "TRAINING Epoch 4/70 Loss 0.1381 Accuracy 0.2123\n",
      "TRAINING Epoch 5/70 Loss 0.1284 Accuracy 0.3260\n",
      "TRAINING Epoch 6/70 Loss 0.1193 Accuracy 0.3993\n",
      "TRAINING Epoch 7/70 Loss 0.1110 Accuracy 0.4717\n",
      "TRAINING Epoch 8/70 Loss 0.1034 Accuracy 0.5310\n",
      "TRAINING Epoch 9/70 Loss 0.0963 Accuracy 0.5867\n",
      "TRAINING Epoch 10/70 Loss 0.0899 Accuracy 0.6397\n",
      "TRAINING Epoch 11/70 Loss 0.0839 Accuracy 0.6577\n",
      "TRAINING Epoch 12/70 Loss 0.0789 Accuracy 0.6943\n",
      "TRAINING Epoch 13/70 Loss 0.0736 Accuracy 0.7330\n",
      "TRAINING Epoch 14/70 Loss 0.0695 Accuracy 0.7567\n",
      "TRAINING Epoch 15/70 Loss 0.0652 Accuracy 0.7687\n",
      "TRAINING Epoch 16/70 Loss 0.0613 Accuracy 0.7937\n",
      "TRAINING Epoch 17/70 Loss 0.0577 Accuracy 0.8200\n",
      "TRAINING Epoch 18/70 Loss 0.0545 Accuracy 0.8330\n",
      "TRAINING Epoch 19/70 Loss 0.0512 Accuracy 0.8497\n",
      "TRAINING Epoch 20/70 Loss 0.0483 Accuracy 0.8617\n",
      "TRAINING Epoch 21/70 Loss 0.0459 Accuracy 0.8633\n",
      "TRAINING Epoch 22/70 Loss 0.0433 Accuracy 0.8860\n",
      "TRAINING Epoch 23/70 Loss 0.0414 Accuracy 0.8927\n",
      "TRAINING Epoch 24/70 Loss 0.0392 Accuracy 0.8980\n",
      "TRAINING Epoch 25/70 Loss 0.0376 Accuracy 0.9047\n",
      "TRAINING Epoch 26/70 Loss 0.0354 Accuracy 0.9213\n",
      "TRAINING Epoch 27/70 Loss 0.0341 Accuracy 0.9197\n",
      "TRAINING Epoch 28/70 Loss 0.0324 Accuracy 0.9300\n",
      "TRAINING Epoch 29/70 Loss 0.0309 Accuracy 0.9407\n",
      "TRAINING Epoch 30/70 Loss 0.0298 Accuracy 0.9383\n",
      "TRAINING Epoch 31/70 Loss 0.0285 Accuracy 0.9467\n",
      "TRAINING Epoch 32/70 Loss 0.0276 Accuracy 0.9480\n",
      "TRAINING Epoch 33/70 Loss 0.0268 Accuracy 0.9483\n",
      "TRAINING Epoch 34/70 Loss 0.0254 Accuracy 0.9583\n",
      "TRAINING Epoch 35/70 Loss 0.0245 Accuracy 0.9607\n",
      "TRAINING Epoch 36/70 Loss 0.0236 Accuracy 0.9633\n",
      "TRAINING Epoch 37/70 Loss 0.0229 Accuracy 0.9653\n",
      "TRAINING Epoch 38/70 Loss 0.0224 Accuracy 0.9683\n",
      "TRAINING Epoch 39/70 Loss 0.0217 Accuracy 0.9700\n",
      "TRAINING Epoch 40/70 Loss 0.0212 Accuracy 0.9710\n",
      "TRAINING Epoch 41/70 Loss 0.0209 Accuracy 0.9727\n",
      "TRAINING Epoch 42/70 Loss 0.0202 Accuracy 0.9743\n",
      "TRAINING Epoch 43/70 Loss 0.0195 Accuracy 0.9783\n",
      "TRAINING Epoch 44/70 Loss 0.0193 Accuracy 0.9777\n",
      "TRAINING Epoch 45/70 Loss 0.0190 Accuracy 0.9790\n",
      "TRAINING Epoch 46/70 Loss 0.0185 Accuracy 0.9810\n",
      "TRAINING Epoch 47/70 Loss 0.0183 Accuracy 0.9797\n",
      "TRAINING Epoch 48/70 Loss 0.0179 Accuracy 0.9790\n",
      "TRAINING Epoch 49/70 Loss 0.0177 Accuracy 0.9797\n",
      "TRAINING Epoch 50/70 Loss 0.0172 Accuracy 0.9807\n",
      "TRAINING Epoch 51/70 Loss 0.0171 Accuracy 0.9817\n",
      "TRAINING Epoch 52/70 Loss 0.0171 Accuracy 0.9837\n",
      "TRAINING Epoch 53/70 Loss 0.0169 Accuracy 0.9827\n",
      "TRAINING Epoch 54/70 Loss 0.0167 Accuracy 0.9887\n",
      "TRAINING Epoch 55/70 Loss 0.0165 Accuracy 0.9863\n",
      "TRAINING Epoch 56/70 Loss 0.0163 Accuracy 0.9833\n",
      "TRAINING Epoch 57/70 Loss 0.0163 Accuracy 0.9857\n",
      "TRAINING Epoch 58/70 Loss 0.0161 Accuracy 0.9843\n",
      "TRAINING Epoch 59/70 Loss 0.0161 Accuracy 0.9860\n",
      "TRAINING Epoch 60/70 Loss 0.0160 Accuracy 0.9867\n",
      "TRAINING Epoch 61/70 Loss 0.0161 Accuracy 0.9857\n",
      "TRAINING Epoch 62/70 Loss 0.0162 Accuracy 0.9837\n",
      "TRAINING Epoch 63/70 Loss 0.0160 Accuracy 0.9843\n",
      "TRAINING Epoch 64/70 Loss 0.0158 Accuracy 0.9877\n",
      "TRAINING Epoch 65/70 Loss 0.0157 Accuracy 0.9890\n",
      "TRAINING Epoch 66/70 Loss 0.0158 Accuracy 0.9890\n",
      "TRAINING Epoch 67/70 Loss 0.0159 Accuracy 0.9887\n",
      "TRAINING Epoch 68/70 Loss 0.0156 Accuracy 0.9867\n",
      "TRAINING Epoch 69/70 Loss 0.0159 Accuracy 0.9867\n",
      "TRAINING Epoch 70/70 Loss 0.0159 Accuracy 0.9883\n",
      "Finished Training\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "#TODO: Vary Hyperparams\n",
    "\n",
    "# All layers hyperparameters\n",
    "NUM_EPOCHS = 70\n",
    "LEARNING_RATE = 0.0005\n",
    "BATCH_SIZE = 32\n",
    "RESNET_LAST_ONLY = False #Fine tunes only the last layer. Set to False to fine tune entire network\n",
    "\n",
    "# Final layer hypterparameters\n",
    "# NUM_EPOCHS = 70\n",
    "# LEARNING_RATE = 0.005\n",
    "# BATCH_SIZE = 256\n",
    "# RESNET_LAST_ONLY = True #Fine tunes only the last layer. Set to False to fine tune entire network\n",
    "\n",
    "root_path = 'data/' #If your data is in a different folder, set the path accodordingly\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "#         transforms.RandomRotation(10, resample=Image.BILINEAR),\n",
    "        # transforms.RandomAffine(10, scale=(0.95, 1.05), resample=Image.BILINEAR),\n",
    "        transforms.Resize(256),\n",
    "#         transforms.RandomCrop(224),\n",
    "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0), ratio=(4/5, 6/5)),\n",
    "#         transforms.CenterCrop(224),\n",
    "        #TODO: Transforms.RandomResizedCrop() instead of CenterCrop(), RandomRoate() and Horizontal Flip()\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# loading datasets with PyTorch ImageFolder\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(root_path, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'test']}\n",
    "\n",
    "# defining data loaders to load data using image_datasets and transforms, here we also specify batch size for the mini batch\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH_SIZE,\n",
    "                                             shuffle=True, num_workers=6)\n",
    "              for x in ['train', 'test']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "#Initialize the model\n",
    "model = PreTrainedResNet(len(class_names), RESNET_LAST_ONLY)\n",
    "model = model.cuda()\n",
    "\n",
    "#Setting the optimizer and loss criterion\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#Begin Train\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train(model, optimizer, scheduler, criterion, epoch+1, NUM_EPOCHS)\n",
    "  \n",
    "print(\"Finished Training\")\n",
    "print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DEbsnh3a7ljw"
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4wyYKmQ91woU"
   },
   "outputs": [],
   "source": [
    "def test(model, criterion, repeats=2):\n",
    "  model.eval()\n",
    "  \n",
    "  test_loss = 0.0\n",
    "  test_acc = 0.0\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    for itr in range(repeats):\n",
    "      for batch_idx, (images, labels) in enumerate(dataloaders['test']):\n",
    "        #move to GPU\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "\n",
    "        #forward\n",
    "        outputs = model.forward(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        test_acc += torch.sum(preds == labels).item()\n",
    "\n",
    "    test_loss /= (dataset_sizes['test']*repeats)\n",
    "    test_acc /= (dataset_sizes['test']*repeats)\n",
    "\n",
    "    print('Test Loss: %.4f Test Accuracy %.4f' % (test_loss, test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "znXWR6oWyl-B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0599 Test Accuracy 0.5641\n"
     ]
    }
   ],
   "source": [
    "test(model, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kNX2g3AYUbM2"
   },
   "source": [
    "# Visualizing the model predictions\n",
    "\n",
    "Only for viusalizing. Nothing to be done here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zd_lkTdoUaOX"
   },
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(1)  # pause a bit so that plots are updated\n",
    "    \n",
    "def visualize_model(model, num_images=8):\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(dataloaders['test']):\n",
    "        #move to GPU\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "       \n",
    "\n",
    "        for j in range(images.size()[0]):\n",
    "            images_so_far += 1\n",
    "            ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "            ax.axis('off')\n",
    "            ax.set_title('class: {} predicted: {}'.format(class_names[labels.data[j]], class_names[preds[j]]))\n",
    "\n",
    "            imshow(images.cpu().data[j])\n",
    "\n",
    "            if images_so_far == num_images:\n",
    "                return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sxjSnLKOJsTW"
   },
   "outputs": [],
   "source": [
    "visualize_model(model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lab2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}